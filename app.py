import re
import io
import zipfile
import tempfile
import random
import time
from datetime import datetime
import const
import pandas as pd
import numpy as np
from scipy.stats import linregress
from scipy.stats import norm
import streamlit as st
import subprocess
import altair as alt
from data_processing.base_data_processor import AWSDataProcessor, ODTDataProcessor, AMDDataProcessor, DataVisualizer
from data_processing.calculate_data import CalculateData, ApplyCondition
from altair import limit_rows, to_values
from data_processing import utils as us
import toolz
t = lambda data: toolz.curried.pipe(data, limit_rows(max_rows=10000), to_values)
alt.data_transformers.register('custom', t)
alt.data_transformers.enable('custom')

# ãƒ–ãƒ©ã‚¦ã‚¶ã‚¿ãƒ–ç­‰ã®è¨­å®š
st.set_page_config(
    page_title="AWSãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒãƒ³",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://www.extremelycoolapp.com/help',
        'Report a bug': "https://www.extremelycoolapp.com/bug",
        'About': "# This is a header. This is an *extremely* cool app!"
    }
)

# ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«
st.title("AWSãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒãƒ³ğŸš€ï¼ˆä»®ï¼‰")
st.write("AWSï¼ŒãŠã‚“ã©ã¨ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†ã—ãŸã‚Šè¨ˆç®—ã—ãŸã‚Šã™ã‚‹ã‚ˆ")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
st.sidebar.header("AWSãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒãƒ³ğŸš€")
page = st.sidebar.radio("Page", [
    "ãƒ‡ãƒ¼ã‚¿æ•´ç†",
    "ãŠã‚“ã©ã¨ã‚Š",
    "PygWalker"
])


# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰csvã‚’dfã«å¤‰æ›ã™ã‚‹é–¢æ•°
@st.cache_data
def convert_df(file):
    return pd.read_csv(file, engine="python", encoding="shift-jis", index_col=0)

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã«dfã‚’csvã«å¤‰æ›ã™ã‚‹é–¢æ•°
@st.cache_data
def convert_csv(df):
    return df.to_csv(index=True).encode('shift-jis')

# zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹é–¢æ•°
@st.cache_data
def create_zip(df_dict):
    buffer = io.BytesIO()
    with zipfile.ZipFile(buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
        for name, df in df_dict.items():
            csv_data = convert_csv(df)
            zip_file.writestr(f"{name}.csv", csv_data)
    buffer.seek(0)
    return buffer

# ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•°ã‚’å®šç¾©
@st.cache_data
def process_data(file):
    file_name = file.name
    processors = {
        "aws": AWSDataProcessor,
        "odt": ODTDataProcessor,
        "amd": AMDDataProcessor
    }
    # ãƒ•ã‚¡ã‚¤ãƒ«åã®è­˜åˆ¥ã¨å‡¦ç†
    for key, ProcessorClass in processors.items():
        if key in file_name.lower():
            processor = ProcessorClass(file)
            processor.load_data()
            return processor

    raise ValueError("å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿å½¢å¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# datatime.indexã®dfã‚’long_dfã«å¤‰æ›ã™ã‚‹é–¢æ•°
def convert_long(df):
    tmp = df.reset_index()
    long_df = tmp.melt(
                id_vars=["datetime"],
                value_vars=df.columns,
                var_name="Category",
                value_name="Value"
                )
    return long_df


# ãƒ‡ãƒ¼ã‚¿æ•´ç†ãƒšãƒ¼ã‚¸
def data_page():
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®é¸æŠ
    file = st.file_uploader(
        ":material/Search: csvãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (ãƒ•ã‚¡ã‚¤ãƒ«åã¯read_meèª­ã‚“ã§ã­)",
        type=["csv"]
        )

    #  ãƒšãƒ¼ã‚¸ã«ã‚¿ãƒ–ã‚’è¿½åŠ 
    tab_data, tab_calc, tab_graphic = st.tabs(["Data", "Calculate", "Graphic"])

    # Dataã‚¿ãƒ–
    with tab_data:
        if file:
            try:
                # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
                file_name = file.name
                processor = process_data(file)
                df = processor.df
                # åˆæœŸå‡¦ç†ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
                if st.checkbox("åˆæœŸå‡¦ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º"):
                    st.write(df)

                # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã§ã‚«ãƒ©ãƒ ã‚’é¸æŠ
                available_columns = processor.df.columns.tolist()
                selected_columns = st.pills(
                    ":material/coffee: ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã‚«ãƒ©ãƒ ã‚’é¸æŠ",
                    available_columns,
                    selection_mode="multi")


                # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é »åº¦ã®å‡¦ç†
                freq_options_display = {
                    "30min": "30min",
                    "D": "daily",
                    "W": "weekly",
                    "M": "monthly",
                    "Q": "quarterly",
                    "Y": "yearly"
                }
                # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é »åº¦ã®é¸æŠ
                selected_freq_display = st.pills(":material/book: ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é »åº¦ã‚’é¸æŠ", freq_options_display.values())
                # é¸æŠã•ã‚ŒãŸé »åº¦ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
                selected_freq_list = next((key for key, value in freq_options_display.items() if value == selected_freq_display), None)
                # st.write(selected_freq_list)

                # é›†è¨ˆæ–¹æ³•
                agg_method = {
                    "mean": "å¹³å‡å€¤",
                    "median": "ä¸­å¤®å€¤",
                    "std": "æ¨™æº–åå·®",
                    "min": "æœ€å°å€¤",
                    "max": "æœ€å¤§å€¤",
                    "sum": "åˆè¨ˆå€¤"
                }
                # é›†è¨ˆæ–¹æ³•ã®é¸æŠ
                selected_method = st.pills(":material/key: é›†è¨ˆæ–¹æ³•ã‚’é¸æŠ", agg_method.values())
                # é¸æŠã•ã‚ŒãŸé »åº¦ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
                selected_method_list = next((key for key, value in agg_method.items() if value == selected_method), None)
                # st.write(selected_method_list)


                # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®è¨­å®šã‚’ä½œæˆ
                column_settings = {}
                for column in selected_columns:
                    column_settings[column] = {
                        "freq": selected_freq_list,
                        "method": selected_method_list
                    }
                # st.write("ç¾åœ¨ã®è¨­å®š")
                # st.write(f"{column_settings}")

                # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®å®Ÿè¡Œãƒœã‚¿ãƒ³ã¨ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ã‚’ä¸¦ã¹ã‚‹
                col1, col2 = st.columns(2)
                # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®å®Ÿè¡Œã¨å®Ÿè¡Œçµæœã®ä¿å­˜
                with col1:
                    if st.button("ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®å®Ÿè¡Œã¨ä¿å­˜"):
                        try:
                            if selected_columns:
                            # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®å®Ÿè¡Œ
                                resampled_dfs = processor.resample_data(column_settings)    # resampled_dfs = {key:df}
                                # st.write(resampled_dfs)     # çµæœã®ç¢ºèª
                                # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                                if "resampled_dfs" not in st.session_state:
                                    st.session_state["resampled_dfs"] = {}
                                # çµæœã‚’session_stateã«è¿½è¨˜ã¾ãŸã¯ä¸Šæ›¸ã
                                st.session_state["resampled_dfs"].update(resampled_dfs)
                                st.success("å‡¦ç†çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                        except ValueError as e:
                            st.error(f"ä¸€åº¦ãƒªã‚»ãƒƒãƒˆã—ã¦ãã ã•ã„ï¼š{e}")
                        except Exception as e:
                                st.error(f"{column}ã®ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š {e}")

                # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
                with col2:
                    if st.button("å‡¦ç†çµæœã‚’ãƒªã‚»ãƒƒãƒˆ"):
                        if "resampled_dfs" in st.session_state:
                            del st.session_state["resampled_dfs"]
                            st.success("å‡¦ç†çµæœã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")

                # å‡¦ç†çµæœã®è¡¨ç¤º
                if st.button("å‡¦ç†çµæœã‚’è¡¨ç¤º"):
                    if "resampled_dfs" in st.session_state and st.session_state["resampled_dfs"]:
                        try:
                            # ãƒªã‚µãƒ³ãƒ—ãƒ«ã•ã‚ŒãŸDataFrameã‚’concatçµåˆã™ã‚‹
                            concat_df = pd.concat(st.session_state["resampled_dfs"].values(), axis=1)
                            # Altairç”¨ã«concat_dfã‚’å¤‰å½¢
                            long_df = convert_long(concat_df)
                            # session_stateã«concat_dfã¨long_dfã‚’ä¿å­˜
                            st.session_state["concat_df"] = concat_df
                            st.session_state["long_df"] = long_df
                        except Exception as e:
                            st.error(f"concatä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š {e}")
                    else:
                        st.error("å…ˆã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

                # concat_dfã¨long_dfãŒsession_stateã«ã‚ã‚Œã°ï¼Œèª­ã¿è¾¼ã‚“ã§tabã‚’ç”Ÿæˆ
                if "concat_df" in st.session_state and "long_df" in st.session_state:
                    concat_df = st.session_state["concat_df"]
                    long_df = st.session_state["long_df"]
                    # data, describeã‚¿ãƒ–ã‚’ç”Ÿæˆ
                    tab1, tab2 = st.tabs(["Data", "Describe"])
                    # DataVisualizerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆ
                    visualizer = DataVisualizer()

                    # Dataã‚¿ãƒ–
                    with tab1:
                        col1, col2 = st.columns([45, 55])
                        with col1:
                            # concat_fã‚’è¡¨ç¤º
                            st.write(concat_df)
                            csv1 = convert_csv(concat_df)   # dfæ›´æ–°å¾Œã‚’csvã«å¤‰æ›
                            # csvã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                            st.download_button(
                                label="Download as csv",
                                data=csv1,
                                file_name=f"{file_name}_concat.csv",
                                mime="text/csv"
                                )
                            # long_dfã‚’è¡¨ç¤º
                            st.write(long_df)
                            csv2 = convert_csv(long_df)     # dfæ›´æ–°å¾Œã‚’csvã«å¤‰æ›
                            st.download_button(
                                label="Download as csv",
                                data=csv2,
                                file_name=f"{file_name}_long.csv",
                                mime="text/csv"
                            )
                        with col2:
                            # å›å¸°åˆ†æã®çµæœã‚’è¨ˆç®—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                            @st.cache_data
                            def regression_stats(df):
                                res = linregress(df[x_category], df[y_category])
                                res_df = pd.DataFrame({
                                    "Metric": ["r-value", "R-squared", "slope", "intercept", "p-value", "std-error", "intercept-stderror"],
                                    "Value": [
                                        res.rvalue,
                                        res.rvalue**2,
                                        res.slope,
                                        res.intercept,
                                        res.pvalue,
                                        res.stderr,
                                        res.intercept_stderr
                                    ]
                                })
                                return res_df

                            # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚«ãƒ†ã‚´ãƒªã‚’å–å¾—
                            categories = concat_df.columns.unique()
                            # ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ
                            if len(categories) == 1:
                                linechart = visualizer.linechart_plot(long_df)
                                st.altair_chart(linechart.interactive())
                            else:
                                # xè»¸ã®ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ
                                x_category = st.selectbox("X-Axis", categories, key="x_category")
                                # xè»¸ã§é¸æŠã•ã‚ŒãŸã‚«ãƒ©ãƒ ã‚’yè»¸ã‹ã‚‰é™¤å¤–
                                y_categories = [cat for cat in categories if cat != x_category]
                                y_category = st.selectbox("Y-Axis", y_categories, key="y_category")
                                # é¸æŠã•ã‚ŒãŸè»¸ã®è»¸å¹…ã‚’è¨ˆç®—ã—ã¦ï¼Œaxis_rangeã«ä¿å­˜
                                axis_range = {
                                    "x_min": float(concat_df[x_category].min())-abs(float(concat_df[x_category].min())*0.25),
                                    "x_max": float(concat_df[x_category].max())+abs(float(concat_df[x_category].min())*0.25),
                                    "y_min": float(concat_df[y_category].min())-abs(float(concat_df[y_category].min())*0.25),
                                    "y_max": float(concat_df[y_category].max())+abs(float(concat_df[y_category].min())*0.25)
                                }
                                # xè»¸ã®ç¯„å›²ã‚’é¸æŠã™ã‚‹ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
                                x_range = st.slider(
                                    "X-range",
                                    min_value=axis_range["x_min"],
                                    max_value=axis_range["x_max"],
                                    value=(axis_range["x_min"], axis_range["x_max"])
                                )
                                # yè»¸ã®ç¯„å›²ã‚’é¸æŠã™ã‚‹ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
                                y_range = st.slider(
                                    "Y-range",
                                    min_value=axis_range["y_min"],
                                    max_value=axis_range["y_max"],
                                    value=(axis_range["y_min"], axis_range["y_max"])
                                )

                                # é¸æŠã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã‚’dfã¨ã—ã¦è¿”ã™
                                tmp = concat_df[[f"{x_category}", f"{y_category}"]].reset_index()
                                col1, col2 = st.columns([72, 28])
                                # æ•£å¸ƒå›³ã®æç”»
                                with col1:
                                    scatter_layer = visualizer.scatter_plot(tmp, x_category, y_category, x_range, y_range)
                                    st.altair_chart(scatter_layer)

                                with col2:
                                    # å›å¸°åˆ†æã®çµæœã‚’è¡¨ç¤º
                                    reg_df = regression_stats(concat_df)
                                    st.table(reg_df)

                    # Describeã‚¿ãƒ–
                    with tab2:
                        col1, col2 = st.columns([40, 60])
                        with col1:
                            st.write(concat_df.describe())  # dfã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
                        with col2:
                            # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
                            @st.cache_data
                            def calc_hist(series, bins):
                                """ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
                                hist, edges = np.histogram(series, bins=bins)
                                return pd.DataFrame({
                                    'count': hist,
                                    'bin_start': edges[:-1],
                                    'bin_end': edges[1:]
                                })
                            # æ­£è¦åˆ†å¸ƒã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
                            @st.cache_data
                            def calc_norm(series, category):
                                """æ­£è¦åˆ†å¸ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
                                # Seriesã‹ã‚‰å¹³å‡Î¼ï¼Œæ¨™æº–åå·®Ïƒã‚’å–å¾—
                                mu, sigma = series.mean(), series.std()
                                # ç¢ºç‡å¯†åº¦é–¢æ•°
                                x = np.linspace(series.min(), series.max(), 100)
                                pdf = norm.pdf(x, mu, sigma)
                                # ã‚«ãƒ†ã‚´ãƒªã‚’è¿½åŠ 
                                df = pd.DataFrame({
                                    "category": category,
                                    "x": x,
                                    "Density":pdf
                                })
                                return df

                            # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚«ãƒ†ã‚´ãƒªåã‚’å–å¾—ã—ã¦ã‚¿ãƒ–ã‚’ç”Ÿæˆ
                            categories = list(long_df["Category"].unique()) + ["box_plot"]
                            tabs = st.tabs(categories)

                            # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’æç”»
                            for i, category in enumerate(categories):
                                with tabs[i]:
                                    if category != "box_plot":
                                        # è©²å½“ã‚«ãƒ†ã‚´ãƒªã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                                        category_df = long_df[long_df["Category"] == category]
                                        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®ãƒ“ãƒ³ã®æ•°ã‚’é¸æŠ
                                        default_bins = 30
                                        select_bins = st.slider(
                                            "ãƒ“ãƒ³æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„",
                                            min_value=10,
                                            max_value=100,
                                            step=5,
                                            value=default_bins,
                                            key=f"slider_{category}"
                                            )
                                        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—
                                        hist_df = calc_hist(category_df["Value"], select_bins)
                                        # æ­£è¦åˆ†å¸ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—
                                        norm_df = calc_norm(category_df["Value"], category)
                                        # çµ±è¨ˆé‡ã‚’å–å¾—
                                        mu = category_df["Value"].mean()
                                        med = category_df["Value"].median()
                                        sigma = category_df["Value"].std()

                                        # ãƒ©ã‚¤ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æƒ…å ±ã‚’ã¾ã¨ã‚ã‚‹
                                        lines_df = pd.DataFrame({
                                            "Label": ["Median", "Mean", "+1Ïƒ", "-1Ïƒ"],
                                            "Value": [med, mu, mu+sigma, mu-sigma],
                                            "Color": ["red", "green", "yellow", "yellow"],
                                            "Width": [0.5, 0.5, 0.3, 0.3]
                                        })

                                        # ãƒ©ã‚¤ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ç”Ÿæˆ
                                        lines = visualizer.line_plot(lines_df)

                                        # ã‚°ãƒ©ãƒ•ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ç”Ÿæˆ
                                        norm_layer = visualizer.ridge_plot(norm_df)  # ãƒªãƒƒã‚¸ãƒ©ã‚¤ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼
                                        hist_layer = visualizer.hist_plot(hist_df, select_bins)    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ¬ã‚¤ãƒ¤ãƒ¼
                                        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã¨ãƒªãƒƒã‚¸ãƒ©ã‚¤ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’åœ§ç¸®
                                        chart_plots = alt.layer(hist_layer, norm_layer).resolve_scale(y='independent').properties(
                                            width=600,
                                            height=400
                                        )
                                        # ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’åœ§ç¸®
                                        chart = chart_plots + lines
                                        # ç®±ã²ã’å›³ã®ãƒ‡ãƒ¼ã‚¿ä½œæˆ
                                        box_layer = visualizer.box_plot(category_df)
                                        chart = alt.hconcat(
                                            chart,
                                            box_layer
                                        ).resolve_scale(color="independent")
                                        st.altair_chart(chart, use_container_width=True)

                                    else:
                                        # box_plotã‚¿ãƒ–ã«ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«ç®±ã²ã’å›³ã‚’æç”»
                                        box_plot = visualizer.box_plot(long_df)
                                        st.altair_chart(box_plot, use_container_width=True)
            except Exception as e:
                    print(f"ã‚¨ãƒ©ãƒ¼ï¼š{e}")

        else:
            st.warning("è§£æã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")


    # calculateã‚¿ãƒ–
    with tab_calc:
        # ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
        if file:
            # session_stateã«ã‚ã‚‹dataframeã‚’èª­ã¿è¾¼ã¿
            if "concat_df" in st.session_state and "long_df" in st.session_state:
                concat_df = st.session_state["concat_df"]
                long_df = st.session_state["long_df"]
                # è¨ˆç®—ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ
                calc_dict = {
                    "ç§»å‹•å¹³å‡": "MA",
                    "æ¡ä»¶åˆ¤å®š": "JUDGE",
                    
                }
                st.selectbox(
                    "è¨ˆç®—ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã—ã¦ãã ã•ã„",[
                        "ç§»å‹•å¹³å‡",
                        "æ¡ä»¶åˆ¤å®š"
                        ]
                    )
            else:
                pass

        else:
            st.warning("è§£æã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")


    # Graphicã‚¿ãƒ–
    with tab_graphic:
        if file:
            # session_stateã«ã‚ã‚‹dataframeã‚’èª­ã¿è¾¼ã¿
            if "concat_df" in st.session_state:
                concat_df = st.session_state["concat_df"]
                # Pygwalkerã®èµ·å‹•
                st.write("ğŸ’¹PygWalkerã§ã‚°ãƒ©ãƒ•ä½œæˆ")
                if st.button("PygWalkerã‚’é–‹ã"):
                    # ç¾åœ¨æ™‚åˆ»ã¨ä¹±æ•°ã§tmpãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½œæˆ
                    suffix = f"{int(time.time())}_{random.randint(0, 9999)}"
                    tmp_file_name = f"pyg_config_{suffix}.pyg"
                    # ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp_file:
                        tmp_file.write(convert_csv(concat_df))
                        tmp_fpath = tmp_file.name
                    # Pygã®èµ·å‹•
                    subprocess.Popen(["streamlit", "run", "pygwalker_app.py", "--", tmp_fpath])
            else:
                st.warning("ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.warning("è§£æã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")


# ãŠã‚“ã©ã¨ã‚Šãƒšãƒ¼ã‚¸ã®å‡¦ç†
def ondotori_page():
    # DataVisualizerã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆ
    visualizer = DataVisualizer()
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰
    files = st.file_uploader(
        ":material/Search: csvãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰",
        type=["csv"],
        accept_multiple_files=True
    )
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
    # ãŠã‚“ã©ã¨ã‚Šãƒ‡ãƒ¼ã‚¿ã®åˆæœŸå‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°
    @st.cache_data
    def odt_process(file):
        processor = ODTDataProcessor(file)
        processor.load_data()
        return processor

    # ãƒªã‚µãƒ³ãƒ—ãƒ«ã™ã‚‹é–¢æ•°
    @st.cache_data
    def resample_df(df, freq_key, method_key):
        df = df.resample(freq_key).agg(method_key)
        df = df.apply(pd.to_numeric, errors='coerce')     # æ•°å€¤ã«å¤‰æ›
        df = df.dropna(how='any')  # æ¬ æå€¤ã‚’å«ã‚€è¡Œã‚’å‰Šé™¤
        return df

    # ãƒªã‚µãƒ³ãƒ—ãƒ«ã—ã¦max, minã‚’å–å¾—ã™ã‚‹é–¢æ•°
    @st.cache_data
    def get_maxmin_df(df, freq_key):
        columns_name = df.columns
        new_df = pd.DataFrame(index=df.resample(freq_key).mean().index)
        for col in columns_name:
            new_df[f"{col}_max"] = df[col].resample(freq_key).agg(max)
            new_df[f"{col}_min"] = df[col].resample(freq_key).agg(min)
        new_df = new_df.apply(pd.to_numeric, errors='coerce')
        new_df = new_df.dropna(how='any')
        return new_df

    # ã‚¿ãƒ–ã®ç”Ÿæˆ
    tab_data, tab_tempcurve, tab_fi, tab_ftjudge = st.tabs(["Data", "Temp curve", "Freezing Index", "FT judge"])

    # Dataã‚¿ãƒ–
    with tab_data:
        if files:
            df = None   # dfã‚’åˆæœŸåŒ–
            # session_stateã®åˆæœŸåŒ–
            if "odt_processed_df" in st.session_state and "odt_processed_df_resample" in st.session_state:
                del st.session_state["odt_processed_df"]
                del st.session_state["odt_processed_df_resample"]

            # åˆæœŸå‡¦ç†ãŒå¿…è¦ãªå ´åˆ
            st.write("åˆæœŸå‡¦ç†ğŸ¸")
            if st.checkbox("ã„ã‚‹"):
                processed_dfs = []

                for idx, file in enumerate(files):
                    # ODTDataProcessorã§åˆæœŸå‡¦ç†
                    processor = odt_process(file)
                    df = processor.df

                    try:
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã« "åœ°ç‚¹_æ·±åº¦" ãŒå«ã¾ã‚Œã‚‹å ´åˆã€ãã®æƒ…å ±ã‚’ã‚«ãƒ©ãƒ åã«åæ˜ 
                        match = re.search(r".*_([^_]*)_([^_]*)\.csv$", file.name)
                        if match:
                            prefix = match.group(1)  # åœ°ç‚¹ã‚’æŠ½å‡ºï¼ˆä¾‹ï¼šhkb, kyrgysï¼‰
                            depth = match.group(2)  # æ·±åº¦ã‚’å–å¾—ï¼ˆä¾‹ï¼š~cmï¼‰
                            df.columns = [f"{prefix}_{depth}" for col in df.columns]
                        else:
                            # ã‚«ãƒ©ãƒ åã«ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ã£ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚«ãƒ©ãƒ åã‚’ç”Ÿæˆ
                            df.columns = [f"{col}_{idx+1}" for col in df.columns]

                        processed_dfs.append(df)

                    except Exception as e:
                        st.error(f"ã‚«ãƒ©ãƒ åã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

                # æ¨ªæ–¹å‘ã«çµåˆ
                if processed_dfs:
                    try:
                        df = pd.concat(processed_dfs, axis=1)
                        st.session_state["odt_processed_df"] = df
                        long_df = convert_long(df)  # long_dfã«å¤‰æ›
                        #st.write(df)
                    except ValueError as e:
                        st.error(f"DataFrameã®çµåˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{e}")
                        e = str(e)
                        if "Duplicate column names" in e:
                            st.error(
                "åŒã˜åœ°ç‚¹ã‚„æ·±åº¦ã®ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼"
                "è©²å½“ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ï¼Œå‰Šé™¤ã™ã‚‹ã‹ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ï¼"
            )


            # åˆæœŸå‡¦ç†ãŒã„ã‚‰ãªã„å ´åˆ
            elif st.checkbox("ã„ã‚‰ãªã„"):
                for idx, file in enumerate(files):
                    # csvãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
                    df = convert_df(file)
                    # æ—¥ä»˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«æŒ‡å®š
                    df["datetime"] = pd.to_datetime(df["datetime"], errors='coerce')
                    df.dropna(subset=["datetime"], inplace=True)
                    df.set_index("datetime", inplace=True)
                    df = df.apply(pd.to_numeric, errors='coerce').dropna()

                    try:
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã« "åœ°ç‚¹_æ·±åº¦" ãŒå«ã¾ã‚Œã‚‹å ´åˆã€ãã®æƒ…å ±ã‚’ã‚«ãƒ©ãƒ åã«åæ˜ 
                        match = re.search(r".*_([^_]*)_([^_]*)\.csv$", file.name)
                        if match:
                            prefix = match.group(1)  # åœ°ç‚¹ã‚’æŠ½å‡ºï¼ˆä¾‹ï¼šhkb, kyrgysï¼‰
                            depth = match.group(2)  # æ·±åº¦ã‚’å–å¾—ï¼ˆä¾‹ï¼š~cmï¼‰
                            df.columns = [f"{prefix}_{depth}" for col in df.columns]
                        else:
                            # ã‚«ãƒ©ãƒ åã«ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ã£ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚«ãƒ©ãƒ åã‚’ç”Ÿæˆ
                            df.columns = [f"{col}_{idx+1}" for col in df.columns]

                        processed_dfs.append(df)

                    except Exception as e:
                        st.error(f"ã‚«ãƒ©ãƒ åã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

                # æ¨ªæ–¹å‘ã«çµåˆ
                if processed_dfs:
                    try:
                        df = pd.concat(processed_dfs, axis=1)
                        st.session_state["odt_processed_df"] = df
                        long_df = convert_long(df)  # long_dfã«å¤‰æ›
                        st.write(df)
                    except ValueError as e:
                        st.error(f"DataFrameã®çµåˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{e}")
                        e = str(e)
                        if "Duplicate column names" in e:
                            st.error(
                "åŒã˜åœ°ç‚¹ã‚„æ·±åº¦ã®ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼"
                "è©²å½“ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ï¼Œå‰Šé™¤ã™ã‚‹ã‹ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ï¼"
            )

            # dfãŒå®šç¾©ã•ã‚ŒãŸå ´åˆï¼Œãƒªã‚µãƒ³ãƒ—ãƒ«å‡¦ç†ã®æœ‰ç„¡ã‚’é¸æŠ
            if df is not None:
                ans = st.radio("ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°", ["ã™ã‚‹", "ã—ãªã„"])
                if ans == "ã™ã‚‹":
                    # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é »åº¦ã®å‡¦ç†
                    freq_options_display = {
                        "30min": "30min",
                        "H": "hourly",
                        "D": "daily",
                        "W": "weekly",
                        "M": "monthly",
                        "Q": "quarterly",
                        "Y": "yearly"
                    }
                    # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é »åº¦ã®é¸æŠ
                    selected_freq_display = st.pills(":material/book: ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é »åº¦ã‚’é¸æŠ", freq_options_display.values())
                    selected_freq_key = next((key for key, value in freq_options_display.items() if value == selected_freq_display), None)

                    # é›†è¨ˆæ–¹æ³•
                    agg_method = {
                        "mean": "å¹³å‡å€¤",
                        "median": "ä¸­å¤®å€¤",
                        "std": "æ¨™æº–åå·®",
                        "min": "æœ€å°å€¤",
                        "max": "æœ€å¤§å€¤",
                        "sum": "åˆè¨ˆå€¤"
                    }
                    # é›†è¨ˆæ–¹æ³•ã®é¸æŠ
                    selected_method = st.pills(":material/key: é›†è¨ˆæ–¹æ³•ã‚’é¸æŠ", agg_method.values())
                    selected_method_key = next((key for key, value in agg_method.items() if value == selected_method), None)

                    # ãƒªã‚µãƒ³ãƒ—ãƒ«å‡¦ç†
                    if selected_freq_key is not None and selected_method_key is not None:
                        resampled_df = resample_df(df, selected_freq_key, selected_method_key)  # ãƒªã‚µãƒ³ãƒ—ãƒ«ã®å®Ÿè¡Œ
                        st.session_state["odt_processed_df_resample"] = resampled_df
                        resampled_long_df = convert_long(resampled_df)
                        # col_data, col_graphã«åˆ†ã‘ã¦å®Ÿè¡Œçµæœã‚’è¡¨ç¤º
                        col_data, col_graph = st.columns([45, 55])

                        # dfã‚’è¡¨ç¤ºã™ã‚‹ã‚«ãƒ©ãƒ 
                        with col_data:
                            col1, col2 = st.columns(2)
                            with col1:
                                st.write(resampled_df.head(100))
                                # resampled_dfã‚’csvã«å¤‰æ›ã—ã¦DL
                                csv1 = convert_csv(resampled_df)
                                st.download_button(
                                    label="Download as csv",
                                    data=csv1,
                                    file_name=f"odt_{selected_method_key}_{selected_freq_key}.csv",
                                    mime="text/csv"
                                )
                                # long_dfã«å¤‰æ›
                                csv2 = convert_csv(resampled_long_df)
                                st.write(resampled_long_df.head(100))
                                st.download_button(
                                    label="Download as csv",
                                    data=csv2,
                                    file_name=f"odt_{selected_method_key}_{selected_freq_key}_long.csv"
                                )
                            with col2:
                                st.write(resampled_df.describe())

                        # dfã®æƒ…å ±ã‚’ã‚°ãƒ©ãƒ•åŒ–ã™ã‚‹ã‚«ãƒ©ãƒ 
                        with col_graph:
                            tab1, tab2 = st.tabs(["linechart_plot", "box_plot"])
                            # æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã®è¡¨ç¤º
                            with tab1:
                                linechart = visualizer.linechart_plot(resampled_long_df).properties(width=650, height=401)
                                st.altair_chart(linechart.interactive())
                            # ç®±ã²ã’å›³ã®è¡¨ç¤º
                            with tab2:
                                boxplot = visualizer.box_plot(resampled_long_df)
                                st.altair_chart(boxplot)
                    else:
                        pass

                # ãƒªã‚µãƒ³ãƒ—ãƒ«å‡¦ç†ã—ãªã„å ´åˆ
                elif ans == "ã—ãªã„":
                    col1, col2 = st.columns(2)

                    with col1:
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write(df)
                            csv2 = convert_csv(df)
                            st.download_button(
                                label="Download as csv",
                                data=csv2,
                                file_name="odt_procesed.csv",
                                mime="text/csv"
                            )
                        with col2:
                            st.write(df.describe())

                    with col2:
                        pass

        else:
            st.warning("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")


    # clacã‚¿ãƒ–
    with tab_tempcurve:
        if files:
            # session_stateã‹ã‚‰å‡¦ç†æ¸ˆã¿ã®dfã‚’å‘¼ã³å‡ºã™
            if "odt_processed_df" in st.session_state:
                df = st.session_state["odt_processed_df"]
                df = resample_df(df, "D", "mean")
                col1, col2 = st.columns([35, 65])
                with col1:
                    # ç§»å‹•å¹³å‡ç·šã®è¨ˆç®—
                    st.write("Â©ï¸ç§»å‹•å¹³å‡ç·šã®è¨ˆç®—")
                    # æ—¥ä»˜ç¯„å›²ã‚’å–å¾—
                    start_date = df.index.min().to_pydatetime()
                    end_date = df.index.max().to_pydatetime()

                    # åˆæœŸå€¤ã‚’1/3ã®æœŸé–“ã«ã™ã‚‹å‡¦ç†ï¼ˆã‚°ãƒ©ãƒ•æç”»ãŒé‡ã„ã‹ã‚‰ï¼‰
                    d_length = end_date - start_date    # timedelta
                    d_lenght = d_length / 3
                    d_value = start_date + d_lenght     # ä½ç½®ã‚’è¨ˆç®—

                    # è¨ˆç®—ã®é–‹å§‹æ—¥ã‚’æŒ‡å®š
                    start = st.date_input(
                        "é–‹å§‹æ—¥",
                        value=start_date,
                        min_value=start_date,
                        max_value=end_date
                    )
                    # è¨ˆç®—ã®çµ‚äº†æ—¥ã‚’æŒ‡å®š
                    end = st.date_input(
                        "çµ‚äº†æ—¥",
                        value=d_value,
                        min_value=start_date,
                        max_value=end_date
                    )

                    # dfã‚’è¨ˆç®—æœŸé–“ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    df = df[start : end]
                    long_df = convert_long(df)
                    # ç§»å‹•å¹³å‡ç·šã®è¨ˆç®—æ¡ä»¶ã®é¸æŠ
                    col3, col4, col5 = st.columns([1, 1, 1])
                    with col3:
                        num1 = st.number_input("MA-1", step=1, min_value=1, max_value=366, value=5)
                    with col4:
                        num2 = st.number_input("MA-2", step=1, min_value=1, max_value=366, value=30)
                    with col5:
                        num3 = st.number_input("MA-3", step=1, min_value=1, max_value=366, value=100)
                    # é¸æŠã•ã‚ŒãŸæ¡ä»¶ã‚’listã«æ ¼ç´
                    MA_list = [num1, num2, num3]
                    # ç§»å‹•å¹³å‡ã‚’è¨ˆç®—ã—ã¦æ–°ã—ã„dfã«ä¿å­˜
                    @st.cache_data
                    def calc_MAs(df, ma_list):
                        """MAã¨step_averageã‚’è¨ˆç®—ã—ã¦dictã§è¿”ã™"""
                        ma_dfs = {}    # ma_dfã‚’æ ¼ç´ã™ã‚‹dict
                        step_averages = {}  # step_averageã‚’æ ¼ç´ã™ã‚‹dict
                        original_columns = df.columns   # å…ƒã®ã‚«ãƒ©ãƒ åã‚’ä¿å­˜
                        for ma in ma_list:
                            calcdata = CalculateData(df)    # CalculateDataã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆ
                            # æ–°ã—ãç§»å‹•å¹³å‡ã‚’è¨ˆç®—ã—ãŸdfã‚’ä½œæˆ
                            ma_df = calcdata.calc_MA(ma)
                            # stepé–“éš”ã®å¹³å‡å€¤ã‚’è¨ˆç®—ã—ã¦æ–°ã—ã„dfã«ä¿å­˜
                            step_average = calcdata.step_average(ma)

                            # ã‚«ãƒ©ãƒ åã«MAæƒ…å ±ã‚’è¿½åŠ 
                            columns_name_ma = {col: f"{col}_MA{ma}" for col in original_columns}
                            columns_name_step = {col: f"{col}_step{ma}" for col in original_columns}
                            ma_df = ma_df.rename(columns=columns_name_ma)
                            step_average = step_average.rename(columns=columns_name_step)
                            # dictã«ä¿å­˜
                            ma_dfs[f"MA{ma}"] = ma_df
                            step_averages[f"step{ma}"] = step_average
                        return ma_dfs, step_averages


                    # ç§»å‹•å¹³å‡ç·šã®è¨ˆç®—
                    MAs, step_averages = calc_MAs(df, MA_list)
                    # long_dfã«å¤‰æ›
                    MAs_long = {}   # ç§»å‹•å¹³å‡ç·š
                    for key, df in MAs.items():
                        MA_long_df = convert_long(df)
                        MAs_long[key] = MA_long_df
                    step_averages_long = {}     # stepé–“éš”å¹³å‡
                    for key, df in step_averages.items():
                        step_averages_long_df = convert_long(df)
                        step_averages_long[key] = step_averages_long_df


                    # æ¸©åº¦å¤‰åŒ–æ›²ç·šã®è¨ˆç®—
                    temp_curves = {}
                    for key, ma_df in MAs.items():
                        calcdata = CalculateData(ma_df)
                        temp_curve = calcdata.temp_curve()
                        temp_curves[key] = temp_curve

                    # å¹´æ•°ã”ã¨ã«temp_curveã‚’çµåˆã™ã‚‹     {MA5: {2021: temp_curve_df(datetime, hkb_5cm_MA5)}}â†ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
                    temp_curve_dfs = {}    # temp_curve(df)ã‚’å¹´æ•°åˆ¥ã§æ ¼ç´ã™ã‚‹dict
                    for key, year_data in temp_curves.items():
                        #st.write(key)
                        #st.write(year_data)
                        for year, df in year_data.items():
                            #st.write(year)
                            #st.write(df)
                            if year not in temp_curve_dfs:
                                # å¹´ã”ã¨ã®dfã‚’ä½œæˆï¼ˆã“ã“ã«çµåˆã—ã¦ã„ãï¼‰
                                temp_curve_dfs[year] = pd.DataFrame()
                            # yaerã®ã‚«ãƒ©ãƒ ã‚’ä½œæˆ
                            temp_curve_dfs[year]["year"] = year
                            # 1~365ã¾ã§è­˜åˆ¥ã™ã‚‹
                            temp_curve_dfs[year]["Date"] = range(1, len(df) + 1)
                            # MAã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ(dictã§å¹´åˆ¥ã«æ•´ç†ã—ã¦ãŸdfã‚’å¹´ã”ã¨ã®dfã¨ã—ã¦åˆ†ã‘ã¦ç®¡ç†ï¼Œã¤ã¾ã‚Šdictã‹ã‚‰åˆ†é›¢)
                            temp_curve_dfs[year] = pd.concat([temp_curve_dfs[year], df], axis=1)

                    # æœ€å¾Œã«å…¨éƒ¨ç¸¦ã«ãã£ã¤ã‘ã‚‹
                    temp_curve_result = pd.DataFrame()
                    for key, df in temp_curve_dfs.items():
                        temp_curve_result = pd.concat([temp_curve_result, df], axis=0)

                    #st.write(temp_curve_result)
                    key_year = list(temp_curve_dfs.keys())
                    #st.write(temp_curve_dfs[key_year[0]])

                    # long_dfã«å¤‰æ›
                    temp_curve_result_long = temp_curve_result.melt(
                        id_vars=["year", "Date"],
                        value_vars=temp_curve_result.columns,
                        var_name="Category",
                        value_name="Value"
                    )
                    #st.write(temp_curve_result_long)
                    #st.write(temp_curve_result_long.columns)
                    temp_curve_long_dfs = {}
                    for year, df in temp_curve_dfs.items():
                        temp_curve_long_dfs[year] = df.melt(
                            id_vars=["year", "Date"],
                            value_vars=df.columns,
                            var_name="Category",
                            value_name="Value"
                        )

                    # MAsã¨tempcurve_dfsã‚’çµåˆï¼ˆdictï¼‰
                    result_to_zip = dict(**MAs, **step_averages, **temp_curve_dfs)
                    result_to_zip_long = dict(**MAs_long, **step_averages_long, **temp_curve_long_dfs)
                    # zipãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
                    zip_buffer1 = create_zip(result_to_zip)
                    zip_buffer2 = create_zip(result_to_zip_long)
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    if zip_buffer1:
                        st.write("è¨ˆç®—çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                        st.download_button(
                            "Download as zip",
                            data=zip_buffer1,
                            file_name="temp_curves.zip",
                            mime="application/zip"
                            )
                    else:
                        st.warning("è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ")


                # ã‚°ãƒ©ãƒ•ã®æç”»
                with col2:
                    # æ¸©åº¦å¤‰åŒ–æ›²ç·šã®æç”»
                    # æç”»ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠ
                    tc_categories = sorted(temp_curve_result_long["Category"].unique(), reverse=True)
                    tc_selected_category = st.multiselect(
                        "æç”»ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
                        options=tc_categories,
                        default=tc_categories[:3],
                        max_selections=5,
                    )
                    # æç”»ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãŒé¸æŠã•ã‚ŒãŸã‚‰æç”»
                    if tc_selected_category is not None:
                        selected_df = temp_curve_result_long[temp_curve_result_long["Category"].isin(tc_selected_category)]
                        #st.write(selected_df)
                        # ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚’ä½œæˆ
                        year_selector = alt.selection_multi(
                            fields=["year"],
                            bind=alt.binding_select(options=selected_df["year"].unique()),
                            name="year"
                            #init={"year": sorted(selected_df["year"].unique())[0]}
                        )
                        chart = visualizer.linechart_plot(selected_df, datetime=False, col="Date", dtype="Q")
                        chart = chart.encode(
                            strokeDash="year:N",
                            tooltip=["year"]
                        ).add_selection(year_selector).transform_filter(year_selector)
                        st.altair_chart(chart)

                    # ç§»å‹•å¹³å‡ç·šã®æç”»
                    if st.checkbox("ç§»å‹•å¹³å‡ç·šã®è¡¨ç¤º"):
                        # å„dfã‚’ç¸¦ã«çµåˆã™ã‚‹
                        df_list = [long_df] + list(MAs_long.values())
                        combined_df = pd.concat(df_list, ignore_index=True)     # ç¸¦æ–¹å‘ã«çµåˆ
                        combined_df = combined_df.sort_values("Category", ascending=False)
                        combined_df["datetime"] = pd.to_datetime(combined_df["datetime"])
                        # æç”»ã™ã‚‹Categoryã‚’é¸æŠ
                        MAs_categories = sorted(combined_df["Category"].unique(), reverse=True)
                        selected_category = st.multiselect(
                            "æç”»ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
                            options=MAs_categories,
                            default=MAs_categories[:3],
                            max_selections=5,
                            key="select1"
                        )
                        # ã‚«ãƒ†ã‚´ãƒªãŒé¸æŠã•ã‚ŒãŸã‚‰æç”»
                        if selected_category is not None:
                            # é¸æŠã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã‚’altairç”¨ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                            selected_df = combined_df[combined_df["Category"].isin(selected_category)]
                            chart = visualizer.linechart_plot(selected_df)
                            st.altair_chart(chart)
                        else:
                            pass


                        # stepé–“éš”å¹³å‡ç·šã®æç”»
                        df_list2 = [long_df] + list(step_averages_long.values())
                        combined_df2 = pd.concat(df_list2, ignore_index=True)
                        combined_df2 = combined_df2.sort_values("Category", ascending=False)
                        combined_df2["datetime"] = pd.to_datetime(combined_df2["datetime"])
                        # æç”»ã™ã‚‹Categoryã‚’é¸æŠ
                        step_averages_categories = sorted(combined_df2["Category"].unique(), reverse=True)
                        selected_category2 = st.multiselect(
                            "æç”»ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
                            options=step_averages_categories,
                            default=step_averages_categories[:3],
                            max_selections=5,
                            key="select2"
                        )
                        # ã‚«ãƒ†ã‚´ãƒªãŒé¸æŠã•ã‚ŒãŸã‚‰æç”»
                        if selected_category2 is not None:
                            # é¸æŠã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã‚’altairç”¨ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                            selected_df2 = combined_df2[combined_df2["Category"].isin(selected_category2)]
                            chart = visualizer.linechart_plot(selected_df2)
                            st.altair_chart(chart)
                        else:
                            pass
        else:
            st.warning("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")


    with tab_fi:
        if files:
            # session_stateã‹ã‚‰å‡¦ç†æ¸ˆã¿ã®dfã‚’å‘¼ã³å‡ºã™
            if "odt_processed_df" in st.session_state:
                df = st.session_state["odt_processed_df"]
                df = resample_df(df, "D", "mean")
                col1, col2 = st.columns([35, 65])
                with col1:
                    # ç©ç®—å¯’åº¦ã®è¨ˆç®—
                    st.write("Â©ï¸FIãƒ»TDDã®è¨ˆç®—")
                    # æ—¥ä»˜ç¯„å›²ã‚’å–å¾—
                    start_date = df.index.min().to_pydatetime()
                    end_date = df.index.max().to_pydatetime()

                    # åˆæœŸå€¤ã‚’1/3ã®æœŸé–“ã«ã™ã‚‹å‡¦ç†ï¼ˆã‚°ãƒ©ãƒ•æç”»ãŒé‡ã„ã‹ã‚‰ï¼‰
                    d_length = end_date - start_date    # timedelta
                    d_lenght = d_length / 3
                    d_value = start_date + d_lenght     # ä½ç½®ã‚’è¨ˆç®—

                    # è¨ˆç®—ã®é–‹å§‹æ—¥ã‚’æŒ‡å®š
                    start_FI = st.date_input(
                        "é–‹å§‹æ—¥",
                        value=start_date,
                        min_value=start_date,
                        max_value=end_date,
                        key="start2"
                    )
                    # è¨ˆç®—ã®çµ‚äº†æ—¥ã‚’æŒ‡å®š
                    end_FI = st.date_input(
                        "çµ‚äº†æ—¥",
                        value=d_value,
                        min_value=start_date,
                        max_value=end_date,
                        key="end2"
                    )
                    # dfã‚’è¨ˆç®—æœŸé–“ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    df = df[start_FI : end_FI]
                    calcdata = CalculateData(df)

                    # FIã®è¨ˆç®—
                    num = st.number_input(
                        "é–¾å€¤",
                        min_value=-100.0,
                        max_value=100.0,
                        value=0.0,
                        step=0.1,
                        format="%0.1f",
                        help="mâ„ƒä»¥ä¸‹ã‚’çµ¶å¯¾å€¤ã§åŠ ç®—ï¼ä¾‹ï¼‰m=0ã®ã¨ãï¼Œ[-1, 0, 1, -2] â†’ A. 3â„ƒ"
                    )
                    df_FI = calcdata.calc_FI(num)
                    #st.write(df_FI)

                    # TDDã®è¨ˆç®—
                    df_TDD = calcdata.calc_TDD()
                    #st.write(df_TDD)

                    # FIã¨TDDã‚’çµåˆã—ã¦è¡¨ç¤ºï¼Œãã®å¾Œdescribe
                    df_FI_TDD = pd.concat([df_FI, df_TDD], axis=1).drop_duplicates()
                    col3, col4 = st.columns([55, 45])
                    with col3:
                        st.write(df_FI_TDD)
                    with col4:
                        st.write(df_FI_TDD.describe())

                    # df, FIã¨TDDã®çµæœã‚’çµåˆ
                    df = pd.concat([df, df_FI, df_TDD], axis=1).drop_duplicates()

                    # æœˆã”ã¨ã«é›†è¨ˆã—ãŸãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
                    df_months = us.df_groups(df, freq_key="M")

                    # FIã¨TDDã®zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                    result = dict(**{"FI": df_FI, "TDD": df_TDD}, **df_months)

                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    zip_buffer_FI = create_zip(result)
                    if zip_buffer_FI:
                        st.write("è¨ˆç®—çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                        st.download_button(
                            "Download as zip",
                            data=zip_buffer_FI,
                            file_name="FI_TDD.zip",
                            mime="application/zip"
                            )
                    else:
                        st.warning("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")


                with col2:
                    # df(FI, TDDè¿½åŠ æ¸ˆ)ã‚’long_dfã«å¤‰æ›
                    df_long = convert_long(df_FI_TDD)
                    # ã‚«ãƒ†ã‚´ãƒªã®é¸æŠ
                    df_categories = sorted(df_long["Category"].unique())
                    selected_category = st.multiselect(
                        "æç”»ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
                        options=df_categories,
                        default=df_categories[:3],
                        max_selections=5,
                    )
                    # ã‚°ãƒ©ãƒ•ã®æç”»
                    if selected_category is not None:
                        visualizer = DataVisualizer()
                        selected_df = df_long[df_long["Category"].isin(selected_category)]
                        chart = visualizer.linechart_plot(selected_df)
                        st.altair_chart(chart)
                        pass


        else:
            st.warning("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")


    @st.cache_data
    def apply_condition(df, freq_key):
        ac = ApplyCondition(df, freq_key=freq_key)
        return ac
    # FT judgeã‚¿ãƒ–
    with tab_ftjudge:
        if files:
            # session_stateã‹ã‚‰å‡¦ç†æ¸ˆã¿ã®dfã‚’å‘¼ã³å‡ºã™
            if "odt_processed_df" in st.session_state:
                df = st.session_state["odt_processed_df"]
                col1, col2 = st.columns([35, 65])

                with col1:
                    st.write("Â©ï¸å‡çµèè§£åˆ¤å®š")

                    # æ—¥ä»˜ç¯„å›²ã‚’å–å¾—
                    start_date = df.index.min().to_pydatetime()
                    end_date = df.index.max().to_pydatetime()

                    # åˆæœŸå€¤ã‚’1/3ã®æœŸé–“ã«ã™ã‚‹å‡¦ç†ï¼ˆé©å½“ï¼‰
                    d_length = end_date - start_date    # timedelta
                    d_lenght = d_length / 3
                    d_value = start_date + d_lenght     # ä½ç½®ã‚’è¨ˆç®—

                    # è¨ˆç®—ã®é–‹å§‹æ—¥ã‚’æŒ‡å®š
                    start_judge = st.date_input(
                        "é–‹å§‹æ—¥",
                        value=start_date,
                        min_value=start_date,
                        max_value=end_date,
                        key="start3"
                    )
                    # è¨ˆç®—ã®çµ‚äº†æ—¥ã‚’æŒ‡å®š
                    end_judge = st.date_input(
                        "çµ‚äº†æ—¥",
                        value=d_value,
                        min_value=start_date,
                        max_value=end_date,
                        key="end3"
                    )
                    # dfã‚’è¨ˆç®—æœŸé–“ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    df = df[start_judge : end_judge]


                    # FTjudgeã®å®Ÿè¡Œ
                    ac = apply_condition(df, freq_key="D")
                    ft_df = ac.judge_freeze()
                    ft_total = ac.get_count()

                    # æœˆã”ã¨ã«é›†è¨ˆ
                    result = us.df_groups(ft_df, freq_key="M")

                    col3, col4 = st.columns([60, 40])
                    with col3:
                        # ã‚«ã‚¦ãƒ³ãƒˆåˆ—ã‚’åŠ ãˆã¦dfã‚’è¡¨ç¤º
                        st.write(us.add_count_row(ft_df))
                    with col4:
                        st.write(ft_total)

                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    result = dict(**result, **{"total": us.add_count_row(ft_df)})
                    zip_buffer_FT = create_zip(result)
                    if zip_buffer_FT:
                        st.write("è¨ˆç®—çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                        st.download_button(
                            "Download as zip",
                            data=zip_buffer_FT,
                            file_name="FTjudge.zip",
                            mime="application/zip"
                            )
                    else:
                        st.warning("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")


                # ã‚°ãƒ©ãƒ•ã®æç”»
                with col2:
                    pass



# PygWalkerãƒšãƒ¼ã‚¸ã®å‡¦ç†
def Pyg_page():
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®é¸æŠ
    file = st.file_uploader(
        ":material/Search: csvãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["csv"]
        )
    if file:
        df = pd.read_csv(file, engine='python', encoding="shift-jis")
        if st.button("PygWalkerã‚’é–‹ã"):
            # ç¾åœ¨æ™‚åˆ»ã¨ä¹±æ•°ã§tmpãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½œæˆ
            suffix = f"{int(time.time())}_{random.randint(0, 9999)}"
            tmp_file_name = f"pyg_config_{suffix}.pyg"
            # ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp_file:
                tmp_file.write(convert_csv(df))
                tmp_fpath = tmp_file.name
            # Pygã®èµ·å‹•
            subprocess.Popen(["streamlit", "run", "pygwalker_app.py", "--", tmp_fpath])
    else:
        st.warning("è§£æã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")


# pageã®é¸æŠã¨å‡¦ç†
if page == "ãƒ‡ãƒ¼ã‚¿æ•´ç†":
    data_page()

# ãŠã‚“ã©ã¨ã‚Š
elif page == "ãŠã‚“ã©ã¨ã‚Š":
    ondotori_page()

# PygWalker
elif page == "PygWalker":
    Pyg_page()
else:
    pass